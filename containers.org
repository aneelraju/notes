* containers notes
** docker
*** udemy - docker mastery: the complete toolset from a docker captain - bret fisher
**** course introduction and docker setup
***** getting course resources
      + resources
        + https://github.com/bretfisher/udemy-docker-mastery - course repository
***** installing docker: the fast way
      + installation
        + ubuntu:xenial64
 	  + install docker-ce
  	    + % sudo apt-get remove docker docker-engine docker.io; # remove old versions
            + % sudo apt-get update; # update the apt package index
	    + % sudo apt-get install apt-transport-https ca-certificates curl software-properties-common; # install packages to allow apt to use repository over HTTPS
	    + % curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -; # add docker's official GPG key
	    + % sudo apt-key fingerprint 0EBFCD88; # verify key with the fingerprint
	    + % sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"; # set up stable repository
	    + % sudo apt-get update; # update the apt package index
	    + % sudo apt-get install docker-ce; # install latest version of docker ce
	    + % sudo docker run hello-world
	    + to avoid typing sudo (not recommended)
	      + % sudo usermod -aG docker <user>; # add <user> to docker group
	      + relogin
          + install docker-compose
	    + % sudo curl -L https://github.com/docker/compose/releases/download/1.17.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose; # download and install docker compose
	    + % sudo chmod +x /usr/local/bin/docker-compose
	    + % docker-compose --version
	    + % sudo curl -L https://raw.githubusercontent.com/docker/compose/1.17.0/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose; # Place following script in /etc/bash_completion.d/
	    + re-login
          + install docker-machine
	    + % curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` > /tmp/docker-machine ; # downlaod docker machine and extract to your PATH
            + % sudo chmod +x /tmp/docker-machine
            + % sudo cp /tmp/docker-machine /usr/local/bin/docker-machine
	    + % docker-machine version; # check docker machine
	    + % scripts=( docker-machine-prompt.bash docker-machine-wrapper.bash docker-machine.bash ); for i in "${scripts[@]}"; do sudo wget https://raw.githubusercontent.com/docker/machine/v0.13.0/contrib/completion/bash/${i} -P /etc/bash_completion.d; done
	    + re-login
	  + because docker-compose and docker-machine are installed manually, make sure you check for latest version frequently
      + run more nodes: % docker-machine create --driver
        + virtualbox, aws etc. https://docs.docker.com/machine/drivers/
      + resources
        + https://labs.play-with-docker.com - run one or more docker instances inside your browser
        + https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/ - ubuntu docker installation
        + https://get.docker.com; # install docker via running script
	  + % curl -fsSL get.docker.com -o get-docker.sh
	  + % sh get-docker.sh
        + https://docs.docker.com/machine/install-machine/ - docker machine install (docker docs)
        + https://docs.docker.com/compose/install/ - docker compose install (docker docs)
        + www.bretfisher.com/shell - customize shell      
***** docker for windows 10 pro/ent: setup and tips
      + resources
        + https://store.docker.com/editions/community/docker-ce-desktop-windows - download docker ce for windows
        + https://desktop.github.com - download github desktop
        + https://code.visualstudio.com - download visual studio code
        + https://docs.docker.com/docker-for-windows/#explore-the-application-and-run-examples - setup tab completion for powershell
        + http://cmder.net - download cmder
        + https://docs.docker.com/docker-for-windows/faqs/ - docker for windows FAQ
***** docker for mac setup and tips
      + resources
        + https://store.docker.com/editions/community/docker-ce-desktop-mac  - docker ce for mac
        + https://www.iterm2.com - iterm2
        + https://docs.docker.com/docker-for-mac/#installing-bash-completion - installing bash completion on mac
        + https://brew.sh - installing homebrew (the brew cli)
***** docker for linux setup and tips
      + resources
        + https://docs.docker.com/compose/install/ - install docker compose 
        + https://docs.docker.com/machine/install-machine/ - install docker machine
**** creating and using containers like a boss
***** check our docker install and config
      + % sudo docker version; # gives version of client and server
      + % sudo docker info; # gives config and setup
      + % sudo docker; # gives list of commands and management commands
      + new syntax "sudo docker <management-commands> <sub-commands>"
***** starting a Nginx web server
      + hub.docker.com - default image "registry"
      + % sudo docker container run --publish 80:80 nginx; # run nginx container
	+ go to "localhost" in browser
	+ "--publish" opened port 80 on the host IP and routes that traffic to the container IP, port 80
	+ % sudo docker container run --publish 80:80 --detach nginx; # to run in background
      + % sudo docker container ls; # lists running containers
      + % sudo docker container stop <container_id>; # stop container
      + % sudo docker container ls -a; # 
      + % sudo docker container run --publish 80:80 --detach --name webhost nginx; # assing container name
      + % sudo docker container logs webhost; # shows logs
      + % sudo docker container top webhost; # lists process running inside container
      + % sudo docker container --help; # list of container commands
      + % sudo docker container rm <container id1> <container id2>; # removes stopped containers
      + % sudo docker container rm -f <container id1> <container id2>; # removes running and stopped containers
***** debrief: what happens when we run a container
      + % sudo docker container run --publish 8080:80 --name webhost -d nginx:1.11 nginx -T; # run nginx version 1.11 and command "nginx -T"
***** container vs vm: it's just a process
      + % sudo docker run --name mongo -d mongo; # run mongodb
      + % sudo docker ps; # lists running containers
      + % ps aux; # lists all running hosts process
      + % ps aux | grep mongo; # filter running mongo process
      + % sudo docker start mongo; # start mongo container
      + resources
        + https://www.youtube.com/watch?v=sK5i-N34im8&feature=youtu.be&list=PLBmVKD7o3L8v7Kl_XXh3KaJl9Qw2lyuFl - docker internals
***** assignment answers: manage multiple containers
      + docs.docker.com and --help are your friend
      + % sudo docker container run -d -p 3306:3306 --name db -e MYSQL_RANDOM_ROOT_PASSWORD=yes mysql; # run mysql db, --e is to pass environment variables
      + % sudo docker container logs db; # check for "GENERATED ROOT PASSWORD" from mysql logs
      + % sudo docker container run -d --name webserver -p 8080:80 httpd; # run apache webserver
      + % sudo docker ps; # checker item PORTS for each container
      + % sudo docker container run -d --name proxy -p 80:80 nginx; # run nginx to act as proxy
      + % sudo docker container ls; # same as "sudo docker ps"
      + % curl localhost; # should give nginx
      + % curl localhost:8080; # should give apache
      + % sudo docker container stop <proxy cont id> <webserver cont id> <db cont id>; # you can check tab completion after "sudo docker container stop <tab>"
      + % sudo docker ps -a
      + % sudo docker container rm <proxy cont id> <webserver cont id> <db cont id>
      + % sudo docker ps -a; # everything is cleaned up
      + % sudo docker image ls; # images are still present
***** what's going on in containers: CLI process monitoring
      + % sudo docker container run -d --name nginx nginex; # run nginx
      + % sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=true mysql; # run mysql
      + % sudo docker container ls
      + % sudo docker container top mysql; # process list in one container
      + % sudo docker container top nginx; # process list in one container
      + % sudo docker container inspect mysql; # details of one container config; shows metadata about the container (startup config, volumes, networking etc)
      + % sudo docker container stats --help; # displays help
      + % sudo docker container stats; # show live performance data for all containers
***** getting a shell inside containers: no need for ssh
      + % sudo docker container run -it --name proxy nginx bash; # start new container interactively, no ssh needed; '-t'='--tty' -> simulates a real terminal like ssh; '-i'='--interactive' -> keep session open to receive terminal input; bash shell if run with -it, it will give you a terminal inside the running container
        + we can do additional things from shell like installing additional packages and etc; '% exit' to exit from shell and container stops
      + % sudo docker container run -it --name ubuntu ubuntu; # full distribution of linux
        + c% apt-get update; # update packages inside ubuntu container
        + c% apt-get install -y curl; # install curl
        + c% curl www.google.com; # running curl inside container
        + c% exit; exit and stops container
      + % sudo docker start -ai ubuntu; # start ubuntu and curl is installed; new run container will not have curl installed; '-a'='--attach', 'i'='--interactive'
      + % sudo docker start --help; #  start command help
      + % sudo docker exec --help; #  exec command help
      + % sudo docker exec -it mysql bash; # run additional command in existing container; bash shell on running container mysql; 
        c% ps aux; # process list inside container
        c% exit; # exit container
      + 'alpine' is another distribution of linux which is a small security focused distribution
      + sudo docker pull alpine; # pull alpine image, has it's own package manager
      + sudo docker container run -it alpine bash; # throws error as bash is not installed
      + sudo docker container run -it alpine sh; # but has shell; package manager is 'apk' which can be used to install bash
      + resources
        + https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg - package management basics:apt,yum,dnf,pkg
***** docker networks: concepts for private and public comms in containers
      + docker networks defaults
        + each container connected to a private virtual network 'bridge'
        + each virtual network routes through NAT firewall on host IP; NAT firewall is docker daemon configuring host IP on its default i/f so that your containers can access internet 
        + all containers on a virtual network can talk to each other without -p
        + best practice is to create a new virtual network for each app
          + network "my_web_app" for mysql and php/apache containers
          + network "my_api" for mongo and nodejs containers
        + defaults work well in many cases, but easy to swap out parts to customize it
        + make new virtual networks and attach containers to more than one virtual network
        + skip virtual networks and use host IP (--net=host)
        + use different docker network drivers to gain new abilities
      + 'docker container run -p' - exposes ports on your machine
      + % sudo docker container run -p 80:80 --name webhost -d nginx; # -p (--publish) publishing port in HOST:CONTAINER format
      + % sudo docker container port webhost; # displays port
      + % sudo docker container inspect --format '{{ .NetworkSettings.IPAddresss }}' webhost; # --format - a common option for formatting the output of commands using "Go templates"; display container ip address which is different that host IP
      + % ifconfig en0; # mac ip address
      + resources
        + https://docs.docker.com/engine/admin/formatting/ - docker's --format for filtering cli output
***** docker networks: cli management of virtual networks
      + a recent june 2017 change, removes ping in nginx; so replace "nginx" to "nginx:latest" which still has ping
      + running docker inside docker (mac)
        + % docker run -v /var/run/docker.sock:/var/run/docker.sock -it ubuntu bash; # run ubuntu container sharing that sock
        + c% apt-get update && apt-get install curl
        + c% curl -sSL https://get.docker.com/ | sh
        + c% docker version
        + c% docker container run hello-world
        + c% exit
      + % sudo docker network ls; # lists all created networks: bridge, host, null; '--network bridge' is default docker virtual network which is NAT'ed behind the HOST IP; '--network host' is gains performance by skipping virtual networks but sacrifices security of container model; '--network none' removes eth0 and only leaves you with localhost interface in container
      + % sudo docker network inspect bridge; # can see list of containers attached to it; IPAM shows default IP's assigned
      + % sudo docker network create my_app_net; # spawns a new virtual network for you to attach containers to
      + % sudo docker network ls; # shows list of networks
      + % sudo docker network --help; # network command help
      + % sudo docker container run -d --name new_nginx --network my_app_net nginx
      + % sudo docker network inspect my_app_net; # new_nginx is on that network
      + % sudo docker network connect <network id1> <network id2>; # connect dynamically creates a NIC in a container on an existing virtual network
      + % sudo docker network inspect <network id1>; # you can see both networks
      + % sudo docker network disconnect <network id1> <network id2>; # disconnect dynamically rmeoves a NIC from a container on a specific virtual network
      + create your apps so frontend/backend sit on same docker network and their inter-communication never leaves host. all externally exposed ports closed by default and must manually expose via -p which is better default security
***** docker networks: dns and how containers find each other
      + static IP's and using IP's for talking to containers is an anti-patern. do your best to avoid it
      + docker daemon has a built in DNS server that containers use by default
      + % sudo docker container ls
      + % sudo docker network inspect <my_app_net network id>; # not default network brigde
      + dns default names, docker defaults the hostname to the container's name, but you can also set aliases
      + % sudo docker container run -d --name my_nginx --network my_app_net; # my_app_net contains two containers
      + % sudo docker container exec -it my_nginx ping new_nginx; # ping new_nginx from my_nginx
      + % sudo docker container exec -it new_nginx ping my_nginx; # ping my_nginx from new_nginx
      + % sudo docker network ls; # default bridge doesn't have default dns server, need to use --link, it's easier to create new network than bridge -l; docker compose makes it easier for dns
***** assignment answers: using containers for cli testing
      + % sudo docker container run --rm -it centos:7 bash
        + c% yum update curl
        + c% curl --version
        + c% exit
      + % sudo docker container run --rm -it ubuntu:14.04 bash
        + c% apt-get update && apt-get install -y curl
        + c% curl --version
        + c% exit
      + % sudo docker ps -a; # both centos and ubuntu disappears
***** assignment answers: dns round robin test
      + From docker engine 1.11, we can have multiple containers on a created network respond to the same DNS address
      + 'elasticsearch' is becoming popular, is RESTful search and analytics engine
      + % sudo docker network create dude
      + % sudo docker container run -d --net dude --net-alias search elasticsearch:2
      + % sudo docker container run -d --net dude --net-alias search elasticsearch:2
      + % sudo docker container ls
      + % sudo docker container run --rm --net dude alpine nslookup search; # shows two dns entries
      + % sudo docker container run --rm --net dude centos curl -s search:9200; # gives first container
      + % sudo docker container run --rm --net dude centos curl -s search:9200; # gives second container in random fashion
      + % sudo docker container ls
      + % sudo docker container rm <container 1> <container 2>
**** container images, where to find them and how to build them
***** what's an image (and what isn't)
      + resources
        + https://github.com/moby/moby/blob/master/image/spec/v1.md - official docker image specification
***** the mighty hub: using docker hub registry images
      + 'https://hub.docker.com' # docker hub
        + official images are great way to start
      + % sudo docker pull nginx; # pulls nginx latest version
      + % sudo docker pull nginx:1.11.9; # pulls nginx 1.11.9 version, especially needed for production development
      + % sudo docker pull nginx:1.11.9-alpine; # 'alpine' is linux distribution which is very small
      + resources
        + https://github.com/docker-library/official-images/tree/master/library - list of official docker images
***** images and their layers: discover the image cache
      + % sudo docker image history nginx:latest; # history show layers of changes made in image
      + % sudo docker image inspect nginx; # inspect returns JSON metadata about the image; gives details of image
      + images are made up of file system changes and metadata; a container is just a single read/write layer on top of image
      + resources
        + https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/ - images and containers from docker docs
***** image tagging and pushing to docker hub
      + % sudo docker image tag --help; # tag assign one or more tags to an image; images are referred as <user>/<repo>:<tag>
      + office repositories live at the "root namespace" of the registry, so they don't need account name in front of repo name
      + % sudo docker pull mysql/mysql-server; # pulls mysql/mysql-server image
      + % sudo docker image tag nginx aneelraju/nginx; # rename image 'nginx' to 'aneelraju/nginx; syntax 'sudo docker image tag 'SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]''
      + % sudo docker login; # 'sudo docker login <server>' defaults to logging in hub, but you can override by adding server url
        + type username and password; # wrote to file ~/.docker/config.json
      + % sudo docker image push aneelraju/nginx; # push uploads changed layers to a image registry (default is hub)
      + % sudo docker image tag aneelraju/nginx aneelraju/nginx:testing
      + % sudo docker image push aneelraju/nginx:testing
      + % sudo docker logout; # always logout from shared machines or servers when done, to protect your account
***** building images: the dockerfile basics
      + 'sudo docker image build -f some-dockerfile'; # builds docker image
      + package manager like apt and yum are one of the reasons to build containers FROM Debian, Ubuntu, Fedora and CentOS
      + environment variables are one reason they were chosen as preferred way to inject key/value is they work everywhere
      + % cp material/udemy-docker-mastery/dockerfile-sample-1 work/. && cd work/dockerfile-sample-1
      + % sudo docker image build -t customnginx .; # builds docker image in current directory
***** building images: extending official images
      + % sudo docker container run -p 80:80 --rm nginx; # default behavior
      + % cp material/udemy-docker-mastery/dockerfile-sample-2 work/. && cd work/dockerfile-sample-2
      + % sudo docker image build -t nginx-with-html .; # as much as possible use popular docker images from docker hub
***** assignment answers: build your own image
      + Dockerfiles are part process workflow and part art
      + % cp material/udemy-docker-master/dockerfile-assignment-1 work/. && cd work/dockerfile-assignment-1
      + prepare dockerfile
      + 'CMD ["executable", "param1", "param2"]'
      + % sudo docker image build -t testnode .
      + % sudo docker container run --rm -p 80:3000 testnode
      + % sudo docker image tag testnode aneelraju/testing-node
      + % sudo docker push aneelraju/testing-node
      + % sudo docker image ls
      + % sudo docker image rm aneelraju/testing-node
      + % sudo docker container run --rm -p 80:3000 aneelraju/testing-node; # downloads from docker hub
**** container lifetime & persistent data: volumes, volumes, volumes
***** container lifetime & persistent data
      + container are usually immutable and ephemeral; "immutable infrastructure": only re-deploy containers, never change
      + container should not mix data with binaries; docker gives us features to ensure these "separation of concerns"
      + for "persistent data" two solutions are available: volumes and bind mounts
      + volumes: make special location outside of container UFS (union file system); container see as a local file path
      + bind mounts: link container path to host path
      + resources
        + https://oreilly.janrainsso.com/static/server.html?origin=https%3A%2F%2Fwww.oreilly.com%2Fideas%2Fan-introduction-to-immutable-infrastructure - intro to immutable infrastructure concepts
        + https://12factor.net - the 12-factor app (everyone should read: key to cloud native app design, deployment and operation)
        + https://medium.com/@kelseyhightower/12-fractured-apps-1080c73d481c - 12 fractured apps (a follow-up to 12-factor, a greate article on how to do 12F correctly in containers)
***** persistent data: data volumes
      + VOLUME command in Dockerfile; # search Dockefile for official mysql in docker file (best way to learn dockerfile best practices); creates and assign volumes; volumes needs manual deletion
      + % sudo docker pull mysql
      + % sudo docker image inspect mysql; # under Config check for "Volumes"
      + % sudo docker container run -d --name mysql -e MYSQL_ALLOW_EMTPY_PASSWORD=True mysql
      + % sudo docker container inspect mysql; # inspect for Mounts and Volumes
      + % sudo docker volume ls; # shows one volume
      + % sudo docker volume inspect <volume name>
      + % sudo docker container run -d --name mysql2 -e MYSQL_ALLOW_EMTPY_PASSWORD=True mysql
      + % sudo docker volume ls; # shows two volumes
      + % sudo docker container stop mysql
      + % sudo docker container stop mysql2
      + % sudo docker container ls
      + % sudo docker container ls -a
      + % sudo docker volume ls; # volumes still present
      + % sudo docker container rm mysql mysql2
      + % sudo docker volume ls; # volumes still present; data still safe
      + 'named volumes' are friendly way to assing vols to containers
      + % sudo docker container run -d --name mysql -e MYSQL_ALLOW_EMTPY_PASSWORD=True -v mysql-db:/var/lib/mysql mysql; # mysql-db is named volume
      + % sudo docker volume ls
      + % sudo docker volume inspect mysql-db
      + % sudo docker container rm -f mysql; # remove container
      + % sudo docker container run -d --name mysql3 -e MYSQL_ALLOW_EMTPY_PASSWORD=True -v mysql-db:/var/lib/mysql mysql
      + % sudo docker volume ls; # doesn't create new volume
      + % sudo docker container inspect mysql3; # name friendly
      + % sudo docker volume create --help; # 'docker volume create' required to do this before "docker run" to use custom drivers and labels
      + sometime you need to create volumes ahead of run, usually for local development specifying in Dockerfile or in run command is fine
***** persistent data: bind mounting
      + mapping a host file or directory to a container file or directory; basically just two locations pointing to the same files
      + can't use in Dockerfile, must be at container run as bind mount are host specific
      + bind mounts starts with '/' and full path
      + % cd work/dockerfile-sample-2
      + % sudo docker container run -d --name nginx -p 80:80 -v $(pwd):/usr/share/nginx/html nginx; # bind mounts current directory
      + % sudo docker container exec -it nginx bash; # get shell into container
      + c% cd /usr/share/nginx/html; # we can host files 
***** assignment answers: database upgrades with named volumes
      + get volume path from docker hub postgres:9.6.1
      + % sudo docker container run -d --name psql -v psql:/var/lib/postgresql/data postgres:9.6.1
      + % sudo docker container logs -f psql; # -f keeps watching as it runs
      + ctrl-c
      + % sudo docker container stop <container id>
      + % sudo docker container run -d --name psql2 -v psql:/var/lib/postgresql/data postgres:9.6.2
      + % sudo docker container ps -a
      + % sudo docker volume ls; # one volume psql
      + % sudo docker container logs <container id>; # postgress is successfully upgraded
***** assignment answers: edit code running in containers with bind mounts
      + good for local development and local testing (similar to vagrant /vagrant folder); allows you to edit files on host machine
      + "Jekyll" is static site generator; # for a simple web site
      + % cp material/udemy-docker-mastery/bindmount-sample-1 work/. && cd work/bindmount-sample-1
      + % sudo docker run -p 80:4000 -v $(pwd):/site bretfisher/jekyll-serve
      + resources
        + https://jekyllrb.com - jekyll, a static site generator
        + https://hub.docker.com/r/bretfisher/jekyll-serve/ - info about how to use jekyll in a docker container for easy SSG development
**** making it easier with docker compose: the multi-container tools
***** docker compose and the docker-compose.yml file
      + docker componse is a cli tool and configuration file; it is comprised of 2 separate but related things
        + 1. YAML formatted file that describes our solution options for: containers, networks and volumes
        + 2. A cli tool docker-compose used for local dev/test automation with those YAML files
      + % sudo docker-compose --help; # docker compose help
      + % cp material/udemy-docker-mastery/compose-sample-1 work/. && cd work/compose-sample-1
      + go through template.yml, docker-compose.yml, compose-2.yml, compose-3.yml
      + resources
        + http://www.yaml.org/start.html - the yaml format: sample generic yaml file
        + http://www.yaml.org/refcard.html - the yaml format: quick reference
        + https://docs.docker.com/compose/compose-file - docker compose file
        + https://docs.docker.com/compose/compose-file/compose-versioning/ - compose file version differences (docker docs)
        + https://github.com/docker/compose/releases - docker compose release downloads (good for linux users that need to download manually)
        + https://wordpress.com - website using wordpress
        + https://ghost.org - open source professional publishing platform
***** trying out basic compose commands
      + docker-compose cli is not a production-grade tool but idea for local development and test
      + 'docker-compose up' - setup volumes/networks and start all containers
      + 'docker-compose down' - stop all containers and remove cont/vol/net
      + if your projects had a Dockerfile and docker-compose.yml then "new developer onboarding" would be
        + 'git clone github.com/some/software'
        + 'docker-compose up'
      + % cp material/udemy-docker-mastery/compose-sample-2 work/. && cd work/compose-sample-2
      + % sudo docker-compose up; # docker-compose is not installed by default on linux with docker
        + % ctrl-c
      + % sudo docker-compose -d; # to run it in the background
      + % sudo docker-compose logs; # to see logs
      + % sudo docker-compose --help; # docker-compose help
      + % sudo docker-compose ps; # list of running containers
      + % sudo docker-compose top; # streaming running process
      + % sudo docker-compose down; # stop and clean-up running processes
      + resources
        + https://github.com/docker/compose/releases - docker-compose download for linux via github, win/mac already have it
***** assignment answers: build a compose file for a multi-container service
      + 'drupal' is content management system website
      + % cp material/udemy-docker-mastery/compose-assignment-2 work/. && cd work/compose-assignment-2
      + % sudo docker pull drupal
      + % sudo docker image inspect drupal
      + check for exposed ports
      + compose docker-compose.yml file
      + % sudo docker-compose up
      + % sudo docker-compose down -v; # remove volumes as well
      + resources
        + https://www.drupal.org; # opensource content management framework
***** adding image building to compose files
      + % cp material/udemy-docker-mastery/compose-sample-3 work/. && cd work/compose-sample-3
      + % sudo docker-compose up
      + % sudo docker-compose down -rmi local; # remove volumes and images as well
      + resources
        + https://docs.docker.com/compose/compose-file/#build - (docker docs) compose file build options
***** assignment answers: compose for run-time image building and multi-container dev
      + % cp work/compose-assignment-2 work/compose-assignment-3 && cd work/compose-assignment-3
      + edit docker-compose.yml and Dockerfile according to README.md
      + % docker-compose up -d
      + configure drupal and install bootstrap theme
      + % docker-compose down
      + % docker-compose up; # website starts directly without installation process
**** docker services and the power of swarm: built-in orchestration
***** swarm mode: built-in orchestration
      + swarm mode is a clustering solution built inside docker
      + swarm commands (docker swarm/node/service/stack/secret) aren't enabled by default
      + docker service (replaces docker run command on swarm)
        + manager node:
          + RAFT
            + API - Accepts command from client and creates service object
            + Orchestrator - Reconcillation loop for service objects and creates tasks
            + Allocator - Allocates IP addresses to tasks
            + Scheduler - Assigns nodes to tasks
            + Dispatcher - Checks in on workers
        + Worker Node
          + Worker - Connects to dispatcher to check on assigned tasks
          + Executor - Executes the tasks assigned to worker node
      + resources
        + https://www.youtube.com/watch?v=dooPhkXT9yI - docker 1.12 swarm mode deep dive part 1: topology (YouTube)
        + https://www.youtube.com/watch?v=dooPhkXT9yI - docker 1.12 swarm mode deep dive part 2: topology (YouTube)
        + https://speakerdeck.com/aluzzardi/heart-of-the-swarmkit-topology-management - Heart of the SwarmKit: Topology Management (slides)
        + https://www.youtube.com/watch?v=EmePhjGnCXY - Heart of the SwarmKit: Store, Topology & Object Model (YouTube)
        + http://thesecretlivesofdata.com/raft/ - Raft Consensus Visualization (Our Swarm DB and how it stays in sync across nodes)
***** create your first service and scale it locally
      + % sudo docker info; # Displays systemwide info; check for Swarm: inactive
      + % sudo docker swarm init; # create a single node cluster on localhost and make current node as manager
        + lots of PKI and security automation
          + root signing certificate created for our swarm
          + certificate is issued for first manager node
          + join tokens are created
        + raft database created to store root CA, configs and secrets
          + encrypted by default on disk (1.13+)
          + no need for another key/value system to hold orchestration/secrets
          + replicates logs amongst managers via mutual TLS in "control plane"
          + raft ensures consistency esp for cloud deployment
      + % sudo docker node ls; # lists nodes
      + % sudo docker node --help; # docker node help
      + % sudo docker swarm --help; # docker swarm help
      + % sudo docker service --help; # docker service help; # 'docker run' is designed for single cluster and 'docker service' is for multi-node clusters
      + % sudo docker service create alpine ping 8.8.8.8; # gives service id not container id
      + % sudo docker service ls; # lists services
      + % sudo docker service ps <servicename>
      + % sudo docker service update <serviceid> --replicas 3; # scaling up services
      + % sudo docker service ls
      + % sudo docker service ps; # 3 services are run
      + % sudo docker update --help; # docker update help; update configuration of one or more containers
      + % sudo docker service update --help; # update a service without taking service down
      + % sudo docker container rm -f <containerid>; # container is removed but it is removed from behind, service will launch new service
      + % sudo docker service rm <servicename>; # removes containers through service
      + % sudo docker service ls; # service is removed
      + % sudo docker container ls; # containers are removed
      + resources
        + https://docs.docker.com/engine/swarm/services/ - deploy services to a swarm (docker docs)
***** creating a 3-node swarm cluster
      + 'play-with-docker.com'; # only needs a browser, but resets after 4 hours
        + quickly create nodes (3 nodes) and each nodes can talk to each other
        + useful if have slower machine and try quickly online
        + runs docker inside docker and has latest tools installed
      + docker-machine + virtualbox; # free and runs locally, but requires a machine with 8GB memory
        + % sudo docker-machine --help; # docker-machine help
        + % sudo docker-machine create node1; # create node through virtual busy box (light weight linux machine)
        + % sudo docker-machine ssh node1; # ssh to node1
          + or % sudo docker-machine env node1; # displays env
          + % eval $(docker-machine env node1); # copy on command prompt
          + docker terminal commands on node1
      + roll you own
        + docker-machine can provision machines for amazon, azure, do, google etc
        + install docker anywhere with get.docker.com; # preferred method as docker-machine may not be used in production settings
      + digital ocean + docker install
        + cheapest and easiest to start digital service
        + most like a production setup, but costs $5-10/node/month
        + create 3 droplets (node1,node2,node3) on digital ocean with 1vCPU + 1GB standard machine ($10/node/month)
        + % ssh root@<node1ip>
        + node1% curl -sSL https://get.docker.com/ | sh; # install docker
        + % ssh root@<node2ip>
        + node2% curl -sSL https://get.docker.com/ | sh; # install docker
        + % ssh root@<node3ip>
        + node3% curl -sSL https://get.docker.com/ | sh; # install docker
        + node1% sudo docker swarm init --advertise-addr <node1 ip>; # docker swarm init
        + node2% sudo docker swarm join --token SWMTKN-1-2th56plepacrp8d8giiyqrtv86m803ia7kiecrzog9xhd9z26h-1mhl4b3x04l2vutj87olww5cn <node1ip>:2377
        + node3% sudo docker swarm join --token SWMTKN-1-2th56plepacrp8d8giiyqrtv86m803ia7kiecrzog9xhd9z26h-1mhl4b3x04l2vutj87olww5cn <node1ip>:2377
        + node1% sudo docker node ls; # lists 3 nodes where node1 is manager and node 2 and node3 are workers
        + node2% sudo docker node ls; # errors out; node2 and node3 are workers so can't run swarm commands
        + node1% sudo docker node update --role manager node2; # upgrading node2 to manager
        + node2% sudo docker node ls
        + node1% sudo docker swarm join-token manager; # get manager token
        + node3% docker swarm join --token SWMTKN-1-2th56plepacrp8d8giiyqrtv86m803ia7kiecrzog9xhd9z26h-e9fhwpe6yhxb8boa2tix8nv6l <node1ip>:2377; # adding node3 directly as manager
        + node1% sudo docker node ls
        + node1% sudo docker service create --replicas 3 alpine ping 8.8.8.8
        + node1% sudo docker service ls; # list of services
        + node1% sudo docker node ps; # list container runs on node1
        + node1% sudo docker node ps node2; # list container runs on node2
        + node1% sudo docker service ps <service name>; # list of container runs, this is due to routing mesh
        + node1% sudo docker service inspect drupal; # list only node1 ip overlay
        + node1% sudo docker node ls
        + node1% sudo docker node demote node3
        + node3% sudo docker swarm leave
        + node3% sudo docker node rm node3
        + node1% sudo docker node ls
        + node1% sudo docker node demote node2
        + node2% sudo docker swarm leave
        + node2% sudo docker node rm node2
        + node1% sudo docker swarm leave --force; # use --force only on last manager node to leave
      + resources
        + https://www.digitalocean.com/?refcode=b813dfcad8d4&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste - digital ocean coupon for $10
        + https://www.digitalocean.com/community/tutorials/how-to-use-ssh-keys-with-digitalocean-droplets - create and upload a SSH key to digital ocean
        + https://www.bretfisher.com/docker-swarm-firewall-ports/ - docker swarm firewall ports
        + https://www.digitalocean.com/community/tutorials/how-to-configure-custom-connection-options-for-your-ssh-client - configure SSH for saving options for specific connections
***** scaling out with overlay networking
      + '--driver overlay' - creates swarm wide bridge network
      + only for container-to-container traffic inside a single swarm
      + optional IPSec (AES) encryption on network creation
      + each service can be connected to multiple networks (e.g. front-end, back-end)
      + node1% sudo docker network create --driver overlay mydrupal
      + node1% sudo docker network ls
      + node1% sudo docker service create --name psql --network mydrupal -e POSTGRES_PASSWORD=mypasswd postgres; # service can be launched on either of node1, node2 or node3
      + node1% sudo docker service ls
      + node1% sudo docker service ps psql; # psql running on node2
      + node2% sudo docker container logs <container name>
      + node1% sudo docker service create --name drupal --network mydrupal -p 80:80 drupal
      + node1% sudo docker service ls
      + node1% sudo docker service ps drupal; # drupal running on node1
      + node1% watch sudo docker service ls; # linux command watch, to watch services
      + in browser https://<node1ip>; # drupal install; overlay acts like every thing on same sub net
      + all 3 (node1ip, node2ip and node3ip) ip's display drupal website
***** scaling out with routing mesh
      + routing mesh
        + routes ingress (incoming) packets for a service to proper task
        + spans all nodes in swarm
        + uses IPVS from linux kernel
        + load balances swarm services across thier tasks
        + two way this works:
          + container-to-container in a overlay network (uses VIP)
          + external traffic incoming to published ports (all nodes listen)
        + this is stateless load balancing
        + this LB is at OSI layer 3 (TCP), not Layer 4 (DNS)
        + both limitation can be overcome with
          + Nginx or HAProxy LB proxy
          + Docker EE, which comes with built-in L4 web proxy
      + node1% sudo docker service create --name search --replicas 3 -p 9200:9200 elasticsearch:2
      + node1% sudo docker service ps search; # list search ps
      + node1% curl localhost:9200; # elasticsearch basic info
      + node1% curl localhost:9200; # now on different node showing load balancing
      + resources
        + https://docs.docker.com/engine/swarm/ingress/ - use swarm mode routing mesh (docker docs)
***** assignment answers: create a multi-service multi-node web app
      + docker's distributed voting app
      + % cp material/udemy-docker-mastery/swarm-app-13 work/. && cd work/swarm-app-13
      + 1 volume, 2 networks and 5 services needed
      + create the commands needed, spin up services and test app
      + everything is using docker hub images, so no data needed on swarm; don't build on production swarms/cloud as they eat resources)
      + like many computer things, this is 1/2 art and 1/2 science
      + node1% sudo docker service ls; # no services
      + node1% sudo node ls; # node1, node2 and node3 available as managers
      + edit README.md and following instructions
      + node1% sudo docker network create -d overlay backend; # create backend network
      + node1% sudo docker network create -d overlay frontend; # create frontend network
      + node1% sudo docker service create --name vote -p 80:80 --network frontend --replicas 2 dockersamples/examplevotingapp_vote:before
      + node1% sudo docker service create --name redis --network frontend --replicas 1 redis:3.2
      + node1% sudo docker service create --name worker --network frontend --network backend dockersamples/examplevotingapp_worker
      + node1% sudo docker service create --name db --network backend --mount type=volume,source=db-data,target=/var/lib/postgresql/data postgres:9.4
        + '-v' is not support in docker service, it's replaced with '--mount'
      + node1% sudo docker service create --name result --network backend -p 5001:80 dockersamples/examplevotingapp_result:before
      + node1% sudo docker service ls; # all five services are running
      + node1% sudo docker service ps db; # runs on node3
      + node1% sudo docker service ps redis; # runs on node3
      + node1% sudo docker service ps result; # runs on node2
      + node1% sudo docker service ps worker; # runs on node2 and node1
      + node1% sudo docker service logs worker; # runs on node1; worker fails until db is up but service is re-started
      + node1% sudo docker container logs <workercontainername>
      + In browser <node1ip> to vote and <node2ip>:5001 to check result
***** swarm stacks and production grade compose
      + resources
        + https://docs.docker.com/compose/compose-file/#not-supported-for-docker-stack-deploy - features not supported in stack deploy
***** using secrets in swarm services
      + resources
        + https://docs.docker.com/engine/swarm/secrets/ - secrets in compose files (docker docs)
***** full app lifecycle: dev, build and deploy with a single compose design
      + resources
        + https://docs.docker.com/compose/extends/#multiple-compose-files - using multiple compose files (docker docs)
        + https://docs.docker.com/compose/production/ - using compose files in production (docker docs)
**** container registries: image storage and distribution
***** docker hub: digging deeper
      + resources
        + https://hub.docker.com - docker hub
***** docker store: what is it for ?
      + resources
        + https://store.docker.com - docker store
***** docker cloud: CI/CD and server ops
      + resources
        + https://cloud.docker.com - docker cloud
***** understanding docker register
      + resources
        + https://docs.docker.com/registry/configuration/ - registry configuration docs
        + https://docs.docker.com/registry/garbage-collection/ - registry garbage collection
        + https://docs.docker.com/registry/recipes/mirror/ - use registry as a "mirror" of docker hub
**** bonus section
** kubernetes
